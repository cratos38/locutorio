#!/usr/bin/env python3
"""
ML Photo Validator v3.4 - Complete Validation + Identity Verification System
============================================================================

Validaciones implementadas:
- ‚úÖ Detecci√≥n de rostros (face_recognition)
- ‚úÖ Calidad de imagen (nitidez, resoluci√≥n, % rostro)
- ‚úÖ Smart crop (m√°rgenes generosos para peinados)
- ‚úÖ NSFW Detection (NudeNet)
- ‚úÖ OCR - Detecci√≥n de texto (EasyOCR)
- ‚úÖ Objetos prohibidos (YOLOv8)
- ‚úÖ Face Matching - Detecci√≥n de celebridades/suplantaci√≥n
- ‚úÖ AI/Deepfake Detection
- ‚úÖ Identity Verification - Verificaci√≥n con ID/C√©dula - NUEVO en v3.4

Servidor: 192.168.1.159:5000
"""

from flask import Flask, request, jsonify
import face_recognition
import cv2
import numpy as np
import traceback
import time
from PIL import Image
import requests
from io import BytesIO
import base64
import tempfile
import os
import re
import torch
import json
from pathlib import Path
from datetime import datetime

app = Flask(__name__)

# ============================================================================
# CARGAR MODELOS AL INICIO
# ============================================================================
print("üîç Cargando modelos ML...")

# NSFW Detector
print("  ‚Ä¢ NudeNet (NSFW)...", end="", flush=True)
from nudenet import NudeDetector
nsfw_detector = NudeDetector()
print(" ‚úÖ")

# OCR
print("  ‚Ä¢ EasyOCR (texto)...", end="", flush=True)
import easyocr
ocr_reader = easyocr.Reader(['en', 'es'], gpu=False)  # CPU mode
print(" ‚úÖ")

# YOLO (objetos)
print("  ‚Ä¢ YOLOv8 (objetos)...", end="", flush=True)
from ultralytics import YOLO
torch.cuda.is_available = lambda : False  # Forzar CPU
yolo_model = YOLO('yolov8n.pt')
print(" ‚úÖ")

print("‚úÖ Todos los modelos cargados\n")

# ============================================================================
# CONFIGURACI√ìN
# ============================================================================

VALIDATION_CONFIG = {
    'profile': {
        'min_face_percentage': 10,
        'min_sharpness': 50,
        'min_sharpness_review': 30,
        'min_resolution': 400,
        'max_faces': 1,
        'crop_margin': 80,
        'crop_margin_top': 120,
        'crop_margin_bottom': 80,
        'crop_aspect': 'square',
        'target_size': 600,
        'nsfw_enabled': True,
        'ocr_enabled': True,
        'object_detection_enabled': True,
        'face_matching_enabled': True,
        'ai_detection_enabled': True
    },
    'album': {
        # √ÅLBUM P√öBLICO: Solo validar NSFW + OCR (palabras vulgares/propaganda) + Armas/Drogas
        'nsfw_enabled': True,
        'nsfw_strict': True,  # Solo rechazar expl√≠cito, permitir cuestionable
        'ocr_enabled': True,
        'ocr_vulgar_only': True,  # Solo palabras vulgares/obscenas + propaganda
        'object_detection_enabled': True,
        'objects_weapons_drugs_only': True,  # Solo armas + drogas (NO alcohol)
        'auto_delete_weapons_drugs': True,  # Borrar autom√°ticamente armas/drogas
        # NO validar rostros, nitidez, face matching, AI
        'face_detection_enabled': False,
        'face_matching_enabled': False,
        'ai_detection_enabled': False,
        'quality_check_enabled': False,
        'crop_enabled': False  # NO recortar fotos de √°lbum
    }
}

# Objetos prohibidos (YOLO classes)
PROHIBITED_OBJECTS = {
    # PERFIL: Todos los objetos
    'profile': {
        'knife': {'threshold': 0.6, 'severity': 'high', 'auto_delete': False},
        'scissors': {'threshold': 0.6, 'severity': 'medium', 'auto_delete': False},
        'bottle': {'threshold': 0.7, 'severity': 'medium', 'auto_delete': False},
        'wine glass': {'threshold': 0.7, 'severity': 'medium', 'auto_delete': False},
        'cup': {'threshold': 0.8, 'severity': 'low', 'auto_delete': False}
    },
    # √ÅLBUM: Solo armas y drogas (con borrado autom√°tico)
    'album': {
        'knife': {'threshold': 0.6, 'severity': 'high', 'auto_delete': True},
        'scissors': {'threshold': 0.6, 'severity': 'high', 'auto_delete': True},
        # NO validar alcohol en √°lbumes (pueden estar en bar/fiesta)
    }
}

# Palabras vulgares/obscenas (para √°lbumes)
VULGAR_WORDS = [
    'puta', 'puto', 'hijo de puta', 'hijoputa', 'co√±o', 'verga', 'pene', 'polla',
    'tetas', 'culo', 'mierda', 'joder', 'follar', 'chingar', 'mamar', 'chupar',
    'fuck', 'shit', 'bitch', 'asshole', 'dick', 'cock', 'pussy', 'porn', 'sex',
    'xxx', 'nude', 'naked', 'desnudo', 'caliente', 'hot', 'sexy'
]

# URLs de propaganda (otras apps de citas)
PROPAGANDA_DOMAINS = [
    'tinder', 'bumble', 'badoo', 'match', 'okcupid', 'hinge', 'pof', 'plenty',
    'eharmony', 'meetic', 'happn', 'grindr', 'her', 'coffee', 'meetme'
]

# Rutas para face matching
FACE_BLACKLIST_PATH = 'face_blacklist.json'
USER_FACE_DB_PATH = 'user_faces_db.json'

# Cargar listas de embeddings
face_blacklist = {}
user_faces_db = {}

def load_face_databases():
    """Carga las bases de datos de rostros"""
    global face_blacklist, user_faces_db
    
    if os.path.exists(FACE_BLACKLIST_PATH):
        try:
            with open(FACE_BLACKLIST_PATH, 'r') as f:
                data = json.load(f)
                face_blacklist = {k: np.array(v) for k, v in data.items()}
            print(f"‚úÖ Blacklist cargada: {len(face_blacklist)} identidades")
        except Exception as e:
            print(f"‚ö†Ô∏è Error cargando blacklist: {e}")
    else:
        print(f"‚ÑπÔ∏è Blacklist vac√≠a (crear {FACE_BLACKLIST_PATH} para a√±adir celebridades)")
    
    if os.path.exists(USER_FACE_DB_PATH):
        try:
            with open(USER_FACE_DB_PATH, 'r') as f:
                data = json.load(f)
                user_faces_db = {k: np.array(v) for k, v in data.items()}
            print(f"‚úÖ Base de usuarios cargada: {len(user_faces_db)} usuarios")
        except Exception as e:
            print(f"‚ö†Ô∏è Error cargando BD usuarios: {e}")
    else:
        print(f"‚ÑπÔ∏è BD usuarios vac√≠a (se crear√° autom√°ticamente)")

load_face_databases()

def save_user_face_embedding(user_id, face_encoding):
    """Guarda el embedding del rostro de un usuario aprobado"""
    global user_faces_db
    
    try:
        user_faces_db[user_id] = face_encoding
        data_to_save = {k: v.tolist() for k, v in user_faces_db.items()}
        with open(USER_FACE_DB_PATH, 'w') as f:
            json.dump(data_to_save, f)
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Error guardando embedding de usuario {user_id}: {e}")
        return False

# ============================================================================
# FUNCIONES AUXILIARES
# ============================================================================

def resize_image(img, max_size=1200):
    """Redimensiona imagen manteniendo aspect ratio"""
    height, width = img.shape[:2]
    if height <= max_size and width <= max_size:
        return img
    
    if height > width:
        new_height = max_size
        new_width = int(width * (max_size / height))
    else:
        new_width = max_size
        new_height = int(height * (max_size / width))
    
    img_pil = Image.fromarray(img)
    img_pil = img_pil.resize((new_width, new_height), Image.Resampling.LANCZOS)
    return np.array(img_pil)


def download_image(url):
    """Descarga imagen desde URL"""
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    img = Image.open(BytesIO(response.content))
    if img.mode != 'RGB':
        img = img.convert('RGB')
    return np.array(img)


def calculate_face_sharpness(img, face_location, expand_factor=1.3):
    """Calcula nitidez SOLO en zona del rostro"""
    height, width = img.shape[:2]
    top, right, bottom, left = face_location
    
    face_width = right - left
    face_height = bottom - top
    
    margin_x = int(face_width * ((expand_factor - 1.0) / 2))
    margin_y = int(face_height * ((expand_factor - 1.0) / 2))
    
    roi_left = max(0, left - margin_x)
    roi_right = min(width, right + margin_x)
    roi_top = max(0, top - margin_y)
    roi_bottom = min(height, bottom + margin_y)
    
    face_roi = img[roi_top:roi_bottom, roi_left:roi_right]
    face_gray = cv2.cvtColor(face_roi, cv2.COLOR_RGB2GRAY)
    laplacian_var = cv2.Laplacian(face_gray, cv2.CV_64F).var()
    
    return laplacian_var


def check_nsfw(img_array, strict_mode=False):
    """
    Detecta contenido NSFW
    
    Args:
        img_array: imagen como numpy array
        strict_mode: Si True, solo rechazar expl√≠cito (para √°lbumes)
                     Si False, tambi√©n rechazar cuestionable (para perfil)
    """
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
    img_pil = Image.fromarray(img_array)
    img_pil.save(tmp.name, 'JPEG')
    
    try:
        detections = nsfw_detector.detect(tmp.name)
        
        explicit_classes = [
            'FEMALE_BREAST_EXPOSED', 'FEMALE_GENITALIA_EXPOSED',
            'MALE_GENITALIA_EXPOSED', 'BUTTOCKS_EXPOSED', 'ANUS_EXPOSED'
        ]
        
        questionable_classes = [
            'BELLY_EXPOSED', 'FEET_EXPOSED', 'ARMPITS_EXPOSED', 'FEMALE_BREAST_COVERED'
        ]
        
        explicit_detections = []
        questionable_detections = []
        max_confidence = 0.0
        
        for det in detections:
            confidence = det['score']
            class_name = det['class']
            
            if class_name in explicit_classes and confidence > 0.60:
                explicit_detections.append({
                    'part': class_name,
                    'confidence': round(confidence, 3),
                    'box': det['box']
                })
                max_confidence = max(max_confidence, confidence)
            elif class_name in questionable_classes and confidence > 0.70:
                questionable_detections.append({
                    'part': class_name,
                    'confidence': round(confidence, 3),
                    'box': det['box']
                })
                max_confidence = max(max_confidence, confidence)
        
        # Decisi√≥n seg√∫n modo
        if explicit_detections:
            verdict = 'explicit'
            is_nsfw = True
        elif not strict_mode and len(questionable_detections) >= 2:
            # Modo normal (perfil): rechazar cuestionable
            verdict = 'questionable'
            is_nsfw = False
        else:
            verdict = 'safe'
            is_nsfw = False
        
        return {
            'is_nsfw': is_nsfw,
            'verdict': verdict,
            'confidence': round(max_confidence, 3),
            'explicit_detections': explicit_detections,
            'questionable_detections': questionable_detections,
            'strict_mode': strict_mode
        }
    finally:
        os.unlink(tmp.name)


def check_text_content(img_array):
    """Detecta texto en la imagen (OCR) - MODO INTELIGENTE"""
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
    img_pil = Image.fromarray(img_array)
    img_pil.save(tmp.name, 'JPEG')
    
    try:
        result = ocr_reader.readtext(tmp.name)
        
        detected_texts = []
        
        phone_patterns = [
            r'\+?\d{1,3}[-.\s]?\(?\d{1,4}\)?[-.\s]?\d{1,4}[-.\s]?\d{1,9}',
            r'\d{3}[-.\s]?\d{3}[-.\s]?\d{4}'
        ]
        url_pattern = r'(www\.|http://|https://|\.com|\.net|\.org|\.es|\.io|\.me|\.tv)'
        
        banned_words = [
            'link', 'insta', 'instagram', 'telegram', 'venta', 'precio',
            'whatsapp', 'onlyfans', 'only fans', 'suscrib', 'follow',
            'compra', 'buy', 'sell', 'money', 'cash', 'pago', 'payment',
            'promocion', 'promo', 'descuento', 'gratis', 'free',
            'llamar', 'call', 'contacto', 'contact', 'mensaje', 'message',
            'snapchat', 'tiktok', 'twitter', 'facebook', 'youtube',
            'disponible', 'available', 'servicio', 'service'
        ]
        
        has_phone = False
        has_url = False
        has_banned_word = False
        total_text_length = 0
        banned_words_found = []
        
        for detection in result:
            bbox, text, conf = detection
            
            if conf < 0.5:
                continue
            
            text_clean = text.strip()
            text_lower = text_clean.lower()
            
            for pattern in phone_patterns:
                if re.search(pattern, text_clean):
                    has_phone = True
            
            if re.search(url_pattern, text_clean, re.IGNORECASE):
                has_url = True
            
            for banned in banned_words:
                if banned in text_lower:
                    has_banned_word = True
                    if banned not in banned_words_found:
                        banned_words_found.append(banned)
            
            if len(text_clean) > 2:
                total_text_length += len(text_clean)
                detected_texts.append({
                    'text': text_clean,
                    'confidence': round(conf, 3),
                    'bbox': bbox
                })
        
        too_much_text = total_text_length > 50
        should_reject = has_phone or has_url or has_banned_word or too_much_text
        
        reject_reason = []
        if has_phone:
            reject_reason.append("n√∫mero de tel√©fono")
        if has_url:
            reject_reason.append("URL")
        if has_banned_word:
            reject_reason.append(f"palabras prohibidas ({', '.join(banned_words_found)})")
        if too_much_text:
            reject_reason.append(f"demasiado texto ({total_text_length} caracteres)")
        
        return {
            'has_text': len(detected_texts) > 0,
            'has_phone': has_phone,
            'has_url': has_url,
            'has_banned_word': has_banned_word,
            'too_much_text': too_much_text,
            'should_reject': should_reject,
            'reject_reason': ', '.join(reject_reason) if reject_reason else None,
            'text_count': len(detected_texts),
            'total_length': total_text_length,
            'banned_words_found': banned_words_found,
            'detections': detected_texts
        }
    finally:
        os.unlink(tmp.name)


def check_prohibited_objects(img_array):
    """Detecta objetos prohibidos con YOLO"""
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
    img_pil = Image.fromarray(img_array)
    img_pil.save(tmp.name, 'JPEG')
    
    try:
        results = yolo_model(tmp.name, verbose=False)
        
        detected_objects = []
        prohibited_found = []
        
        for box in results[0].boxes:
            cls = int(box.cls[0])
            conf = float(box.conf[0])
            label = yolo_model.names[cls]
            
            detected_objects.append({
                'object': label,
                'confidence': round(conf, 3)
            })
            
            if label in PROHIBITED_OBJECTS:
                threshold = PROHIBITED_OBJECTS[label]['threshold']
                severity = PROHIBITED_OBJECTS[label]['severity']
                
                if conf >= threshold:
                    prohibited_found.append({
                        'object': label,
                        'confidence': round(conf, 3),
                        'severity': severity
                    })
        
        should_reject = len(prohibited_found) > 0
        
        return {
            'has_prohibited': should_reject,
            'prohibited_objects': prohibited_found,
            'all_objects': detected_objects
        }
    finally:
        os.unlink(tmp.name)


def check_face_matching(img_array, face_locations, user_id=None):
    """Detecci√≥n de celebridades/suplantaci√≥n mediante face matching"""
    if not face_locations:
        return {
            'is_match': False,
            'matched_identity': None,
            'confidence': 0.0,
            'should_reject': False,
            'match_type': None
        }
    
    try:
        face_encodings = face_recognition.face_encodings(img_array, face_locations)
        
        if not face_encodings:
            return {
                'is_match': False,
                'matched_identity': None,
                'confidence': 0.0,
                'should_reject': False,
                'match_type': None
            }
        
        current_encoding = face_encodings[0]
        
        # Verificar blacklist
        if face_blacklist:
            for identity, blacklisted_encoding in face_blacklist.items():
                distance = face_recognition.face_distance([blacklisted_encoding], current_encoding)[0]
                
                if distance < 0.6:
                    return {
                        'is_match': True,
                        'matched_identity': identity,
                        'confidence': round(1.0 - distance, 3),
                        'distance': round(distance, 3),
                        'should_reject': True,
                        'match_type': 'blacklist',
                        'message': f"Posible suplantaci√≥n de identidad: {identity}"
                    }
        
        # Verificar rostro de usuario
        if user_id and user_id in user_faces_db:
            approved_encoding = user_faces_db[user_id]
            distance = face_recognition.face_distance([approved_encoding], current_encoding)[0]
            
            if distance < 0.4:
                return {
                    'is_match': True,
                    'matched_identity': f"user_{user_id}",
                    'confidence': round(1.0 - distance, 3),
                    'distance': round(distance, 3),
                    'should_reject': False,
                    'match_type': 'user_verified',
                    'message': "Rostro verificado contra perfil del usuario"
                }
            else:
                return {
                    'is_match': False,
                    'matched_identity': f"user_{user_id}_mismatch",
                    'confidence': round(1.0 - distance, 3),
                    'distance': round(distance, 3),
                    'should_reject': True,
                    'match_type': 'user_mismatch',
                    'message': "El rostro no coincide con el perfil del usuario"
                }
        
        return {
            'is_match': False,
            'matched_identity': None,
            'confidence': 0.0,
            'should_reject': False,
            'match_type': 'no_match',
            'face_encoding': current_encoding
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error en face matching: {e}")
        return {
            'is_match': False,
            'matched_identity': None,
            'confidence': 0.0,
            'should_reject': False,
            'match_type': 'error',
            'error': str(e)
        }


def check_ai_generated(img_array):
    """Detecci√≥n de im√°genes generadas por IA / Deepfakes"""
    try:
        indicators = []
        ai_score = 0.0
        
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        h, w = gray.shape
        region_size = min(256, h // 2, w // 2)
        
        if region_size >= 64:
            y1 = (h - region_size) // 2
            x1 = (w - region_size) // 2
            region = gray[y1:y1+region_size, x1:x1+region_size]
            
            fft = np.fft.fft2(region)
            fft_shift = np.fft.fftshift(fft)
            magnitude = np.abs(fft_shift)
            
            center = region_size // 2
            high_freq_ring = magnitude[center-10:center+10, center-10:center+10]
            high_freq_mean = np.mean(high_freq_ring)
            
            if high_freq_mean < 50:
                ai_score += 0.3
                indicators.append("low_high_frequency")
        
        kernel_size = 15
        local_var = cv2.blur(gray, (kernel_size, kernel_size))
        variance = np.var(local_var)
        
        if variance < 500:
            ai_score += 0.2
            indicators.append("low_texture_variance")
        
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        if edge_density < 0.05:
            ai_score += 0.2
            indicators.append("low_edge_density")
        
        hist_b = cv2.calcHist([img_array], [0], None, [256], [0, 256])
        hist_g = cv2.calcHist([img_array], [1], None, [256], [0, 256])
        hist_r = cv2.calcHist([img_array], [2], None, [256], [0, 256])
        
        def calc_entropy(hist):
            hist = hist / (np.sum(hist) + 1e-7)
            entropy = -np.sum(hist * np.log2(hist + 1e-7))
            return entropy
        
        entropy = (calc_entropy(hist_b) + calc_entropy(hist_g) + calc_entropy(hist_r)) / 3
        
        if entropy < 6.0:
            ai_score += 0.3
            indicators.append("low_color_entropy")
        
        confidence = min(ai_score, 1.0)
        is_ai_generated = confidence >= 0.6
        
        return {
            'is_ai_generated': is_ai_generated,
            'confidence': round(confidence, 3),
            'indicators': indicators,
            'should_reject': is_ai_generated,
            'message': f"Posible imagen generada por IA (confianza: {confidence:.1%})" if is_ai_generated else None
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error en detecci√≥n de IA: {e}")
        return {
            'is_ai_generated': False,
            'confidence': 0.0,
            'indicators': [],
            'should_reject': False,
            'error': str(e)
        }


def smart_crop_face(img, face_location, config):
    """Recorta inteligentemente alrededor del rostro"""
    height, width = img.shape[:2]
    top, right, bottom, left = face_location
    
    face_width = right - left
    face_height = bottom - top
    face_center_x = left + (face_width // 2)
    face_center_y = top + (face_height // 2)
    
    margin_percent = config['crop_margin']
    margin_top_percent = config['crop_margin_top']
    margin_bottom_percent = config['crop_margin_bottom']
    
    margin_x = int(face_width * (margin_percent / 100))
    margin_y_top = int(face_height * (margin_top_percent / 100))
    margin_y_bottom = int(face_height * (margin_bottom_percent / 100))
    
    crop_left = max(0, face_center_x - (face_width // 2) - margin_x)
    crop_right = min(width, face_center_x + (face_width // 2) + margin_x)
    crop_top = max(0, top - margin_y_top)
    crop_bottom = min(height, bottom + margin_y_bottom)
    
    crop_width = crop_right - crop_left
    crop_height = crop_bottom - crop_top
    
    aspect_ratio = config['crop_aspect']
    
    if aspect_ratio == 'square':
        target_ratio = 1.0
    elif aspect_ratio == 'portrait':
        target_ratio = 3.0 / 4.0
    else:
        target_ratio = crop_width / crop_height
    
    current_ratio = crop_width / crop_height
    
    if current_ratio > target_ratio:
        target_height = int(crop_width / target_ratio)
        diff = target_height - crop_height
        crop_top = max(0, crop_top - diff // 2)
        crop_bottom = min(height, crop_bottom + (diff - diff // 2))
    else:
        target_width = int(crop_height * target_ratio)
        diff = target_width - crop_width
        crop_left = max(0, crop_left - diff // 2)
        crop_right = min(width, crop_right + (diff - diff // 2))
    
    cropped = img[crop_top:crop_bottom, crop_left:crop_right]
    
    crop_coords = {
        'left': int(crop_left),
        'top': int(crop_top),
        'right': int(crop_right),
        'bottom': int(crop_bottom),
        'width': int(crop_right - crop_left),
        'height': int(crop_bottom - crop_top)
    }
    
    return cropped, crop_coords


# ============================================================================
# FUNCIONES DE VERIFICACI√ìN DE IDENTIDAD - NUEVO v3.4
# ============================================================================

def detect_id_card(img_array):
    """
    Detecta si hay un documento de identidad en la imagen
    Busca formas rectangulares (tarjetas) con texto estructurado
    """
    try:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # Detectar bordes
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        
        # Encontrar contornos
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        id_card_candidates = []
        
        for contour in contours:
            # Aproximar contorno a pol√≠gono
            epsilon = 0.02 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # Buscar formas rectangulares (4 v√©rtices)
            if len(approx) == 4:
                x, y, w, h = cv2.boundingRect(approx)
                
                # Relaci√≥n de aspecto t√≠pica de una tarjeta ID: 1.5:1 a 2:1
                aspect_ratio = float(w) / h if h > 0 else 0
                
                # Tama√±o m√≠nimo (al menos 15% de la imagen)
                img_area = img_array.shape[0] * img_array.shape[1]
                card_area = w * h
                area_percentage = (card_area / img_area) * 100
                
                if 1.3 < aspect_ratio < 2.2 and area_percentage > 10:
                    id_card_candidates.append({
                        'bbox': (x, y, w, h),
                        'aspect_ratio': aspect_ratio,
                        'area_percentage': area_percentage,
                        'contour': approx
                    })
        
        if id_card_candidates:
            # Tomar el candidato m√°s grande
            best_candidate = max(id_card_candidates, key=lambda x: x['area_percentage'])
            
            return {
                'detected': True,
                'bbox': best_candidate['bbox'],
                'aspect_ratio': round(best_candidate['aspect_ratio'], 2),
                'area_percentage': round(best_candidate['area_percentage'], 2)
            }
        else:
            return {
                'detected': False,
                'bbox': None,
                'aspect_ratio': 0,
                'area_percentage': 0
            }
    
    except Exception as e:
        print(f"‚ö†Ô∏è Error detectando ID card: {e}")
        return {
            'detected': False,
            'error': str(e)
        }


def extract_birthdate_from_ocr(ocr_detections):
    """
    Extrae fecha de nacimiento del texto OCR
    Busca patrones: DD/MM/YYYY, DD-MM-YYYY, DD.MM.YYYY
    """
    date_patterns = [
        r'(\d{1,2})[/-.](\d{1,2})[/-.](\d{4})',  # DD/MM/YYYY
        r'(\d{4})[/-.](\d{1,2})[/-.](\d{1,2})',  # YYYY/MM/DD
    ]
    
    keywords = ['nacimiento', 'birth', 'fecha', 'date', 'nac', 'dob']
    
    found_dates = []
    
    for detection in ocr_detections:
        text = detection['text'].lower()
        
        # Buscar patrones de fecha
        for pattern in date_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                groups = match.groups()
                
                # Determinar orden (DD/MM/YYYY o YYYY/MM/DD)
                if len(groups[0]) == 4:  # YYYY primero
                    year, month, day = int(groups[0]), int(groups[1]), int(groups[2])
                else:  # DD primero
                    day, month, year = int(groups[0]), int(groups[1]), int(groups[2])
                
                # Validar fecha
                if 1900 < year < 2024 and 1 <= month <= 12 and 1 <= day <= 31:
                    # Calcular edad
                    today = datetime.now()
                    age = today.year - year - ((today.month, today.day) < (month, day))
                    
                    found_dates.append({
                        'date': f"{day:02d}/{month:02d}/{year}",
                        'day': day,
                        'month': month,
                        'year': year,
                        'age': age,
                        'text': detection['text']
                    })
    
    if found_dates:
        # Retornar la fecha m√°s probable (la m√°s reciente que tenga sentido)
        valid_dates = [d for d in found_dates if 18 <= d['age'] <= 100]
        if valid_dates:
            return valid_dates[0]
    
    return None


def verify_identity_document(selfie_url, user_id, profile_age):
    """
    Verificaci√≥n completa de identidad con documento
    
    Proceso:
    1. Descarga selfie con ID
    2. Detecta rostros (debe haber 2: usuario + foto del ID)
    3. Detecta documento de identidad
    4. Extrae texto con OCR
    5. Busca fecha de nacimiento
    6. Compara rostros: selfie vs ID, selfie vs perfil
    7. Compara edades
    8. Retorna resultado
    9. BORRA foto inmediatamente
    """
    temp_file_path = None
    start_time = time.time()
    
    try:
        print("\n" + "="*70)
        print("üÜî VERIFICACI√ìN DE IDENTIDAD")
        print(f"üë§ Usuario: {user_id}")
        print(f"üìÖ Edad del perfil: {profile_age} a√±os")
        print(f"üìç URL: {selfie_url[:80]}...")
        print("="*70)
        
        # 1. Descargar imagen
        print("\nüì• Descargando selfie con ID...")
        img_original = download_image(selfie_url)
        print(f"‚úÖ Descargada: {img_original.shape[1]}√ó{img_original.shape[0]} px")
        
        # Guardar temporalmente para procesamiento
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
        temp_file_path = temp_file.name
        img_pil = Image.fromarray(img_original)
        img_pil.save(temp_file_path, 'JPEG')
        temp_file.close()
        
        # Redimensionar para procesamiento
        img_resized = resize_image(img_original, max_size=1200)
        
        # 2. Detectar rostros
        print("\nüîç Detectando rostros...")
        face_locations = face_recognition.face_locations(img_resized)
        num_faces = len(face_locations)
        print(f"‚úÖ Rostros detectados: {num_faces}")
        
        if num_faces == 0:
            return {
                "verdict": "REJECTED",
                "reason": "no_face_detected",
                "message": "No se detect√≥ ning√∫n rostro en la imagen",
                "processing_time": round(time.time() - start_time, 2)
            }
        
        if num_faces == 1:
            return {
                "verdict": "REJECTED",
                "reason": "only_one_face",
                "message": "Se detect√≥ solo 1 rostro. Debe incluir tu rostro Y la foto del documento",
                "processing_time": round(time.time() - start_time, 2)
            }
        
        if num_faces > 3:
            return {
                "verdict": "REJECTED",
                "reason": "too_many_faces",
                "message": f"Se detectaron {num_faces} rostros. Solo debe haber tu rostro y la foto del documento",
                "processing_time": round(time.time() - start_time, 2)
            }
        
        # 3. Detectar documento de identidad
        print("\nü™™ Detectando documento de identidad...")
        id_detection = detect_id_card(img_resized)
        
        if not id_detection.get('detected'):
            return {
                "verdict": "REJECTED",
                "reason": "no_id_card_detected",
                "message": "No se detect√≥ documento de identidad. Aseg√∫rate de que el documento sea visible y est√© en posici√≥n horizontal",
                "id_detection": id_detection,
                "processing_time": round(time.time() - start_time, 2)
            }
        
        print(f"‚úÖ Documento detectado:")
        print(f"   √Årea: {id_detection['area_percentage']:.1f}% de la imagen")
        print(f"   Relaci√≥n de aspecto: {id_detection['aspect_ratio']}")
        
        # 4. Extraer texto con OCR
        print("\nüìù Extrayendo texto del documento (OCR)...")
        ocr_result = ocr_reader.readtext(temp_file_path)
        
        ocr_detections = []
        for bbox, text, conf in ocr_result:
            if conf > 0.3:  # Umbral m√°s bajo para documentos
                ocr_detections.append({
                    'text': text.strip(),
                    'confidence': round(conf, 3)
                })
        
        print(f"‚úÖ Texto extra√≠do: {len(ocr_detections)} elementos")
        
        # 5. Extraer fecha de nacimiento
        print("\nüéÇ Buscando fecha de nacimiento...")
        birthdate_info = extract_birthdate_from_ocr(ocr_detections)
        
        if not birthdate_info:
            return {
                "verdict": "REJECTED",
                "reason": "birthdate_not_found",
                "message": "No se pudo leer la fecha de nacimiento del documento. Aseg√∫rate de que sea legible",
                "ocr_text_count": len(ocr_detections),
                "processing_time": round(time.time() - start_time, 2)
            }
        
        extracted_age = birthdate_info['age']
        print(f"‚úÖ Fecha encontrada: {birthdate_info['date']}")
        print(f"   Edad calculada: {extracted_age} a√±os")
        
        # 6. Comparar edades
        print("\nüìä Verificando edad...")
        age_difference = abs(extracted_age - profile_age)
        age_match = age_difference <= 2  # Tolerancia de ¬±2 a√±os
        
        print(f"   Edad del perfil: {profile_age} a√±os")
        print(f"   Edad del documento: {extracted_age} a√±os")
        print(f"   Diferencia: {age_difference} a√±os")
        print(f"   {'‚úÖ Edad coincide' if age_match else '‚ùå Edad NO coincide'}")
        
        if not age_match:
            return {
                "verdict": "REJECTED",
                "reason": "age_mismatch",
                "message": f"La edad del documento ({extracted_age} a√±os) no coincide con la edad del perfil ({profile_age} a√±os)",
                "extracted_age": extracted_age,
                "profile_age": profile_age,
                "age_difference": age_difference,
                "processing_time": round(time.time() - start_time, 2)
            }
        
        # 7. Extraer embeddings de los rostros
        print("\nüë§ Extrayendo caracter√≠sticas faciales...")
        face_encodings = face_recognition.face_encodings(img_resized, face_locations)
        
        if len(face_encodings) < 2:
            return {
                "verdict": "REJECTED",
                "reason": "insufficient_face_encodings",
                "message": "No se pudieron extraer las caracter√≠sticas faciales necesarias",
                "processing_time": round(time.time() - start_time, 2)
            }
        
        # Determinar cu√°l es el rostro grande (selfie) y cu√°l es el peque√±o (ID)
        face_sizes = []
        for loc in face_locations:
            top, right, bottom, left = loc
            area = (bottom - top) * (right - left)
            face_sizes.append(area)
        
        # Ordenar por tama√±o (el m√°s grande es el selfie)
        sorted_indices = sorted(range(len(face_sizes)), key=lambda i: face_sizes[i], reverse=True)
        selfie_idx = sorted_indices[0]
        id_photo_idx = sorted_indices[1]
        
        selfie_encoding = face_encodings[selfie_idx]
        id_encoding = face_encodings[id_photo_idx]
        
        # 8. Comparar rostro selfie vs rostro del documento
        print("\nüîç Comparando rostro del selfie vs foto del documento...")
        distance_selfie_to_id = face_recognition.face_distance([id_encoding], selfie_encoding)[0]
        match_selfie_to_id = distance_selfie_to_id < 0.5
        confidence_selfie_to_id = round(1.0 - distance_selfie_to_id, 3)
        
        print(f"   Distancia: {distance_selfie_to_id:.3f}")
        print(f"   Confianza: {confidence_selfie_to_id:.1%}")
        print(f"   {'‚úÖ Rostros coinciden' if match_selfie_to_id else '‚ùå Rostros NO coinciden'}")
        
        if not match_selfie_to_id:
            return {
                "verdict": "REJECTED",
                "reason": "face_mismatch_selfie_to_id",
                "message": "El rostro del selfie no coincide con la foto del documento",
                "confidence": confidence_selfie_to_id,
                "distance": round(distance_selfie_to_id, 3),
                "processing_time": round(time.time() - start_time, 2)
            }
        
        # 9. Comparar rostro selfie vs rostro del perfil (si existe)
        match_selfie_to_profile = None
        confidence_selfie_to_profile = None
        
        if user_id in user_faces_db:
            print("\nüîç Comparando rostro del selfie vs perfil del usuario...")
            profile_encoding = user_faces_db[user_id]
            distance_selfie_to_profile = face_recognition.face_distance([profile_encoding], selfie_encoding)[0]
            match_selfie_to_profile = distance_selfie_to_profile < 0.4
            confidence_selfie_to_profile = round(1.0 - distance_selfie_to_profile, 3)
            
            print(f"   Distancia: {distance_selfie_to_profile:.3f}")
            print(f"   Confianza: {confidence_selfie_to_profile:.1%}")
            print(f"   {'‚úÖ Rostros coinciden' if match_selfie_to_profile else '‚ùå Rostros NO coinciden'}")
            
            if not match_selfie_to_profile:
                return {
                    "verdict": "REJECTED",
                    "reason": "face_mismatch_selfie_to_profile",
                    "message": "El rostro del selfie no coincide con el rostro registrado en el perfil",
                    "confidence": confidence_selfie_to_profile,
                    "distance": round(distance_selfie_to_profile, 3),
                    "processing_time": round(time.time() - start_time, 2)
                }
        else:
            print("\n‚ÑπÔ∏è No hay rostro registrado en el perfil, guardando embedding...")
            save_user_face_embedding(user_id, selfie_encoding)
            print("‚úÖ Embedding guardado")
        
        # 10. TODO CORRECTO - VERIFICACI√ìN EXITOSA
        processing_time = round(time.time() - start_time, 2)
        
        print("\n" + "="*70)
        print("‚úÖ IDENTIDAD VERIFICADA")
        print("="*70 + "\n")
        
        return {
            "verdict": "VERIFIED",
            "reason": "identity_confirmed",
            "message": "Identidad verificada exitosamente",
            "checks": {
                "id_card_detected": True,
                "faces_detected": num_faces,
                "birthdate_extracted": birthdate_info['date'],
                "age_match": age_match,
                "extracted_age": extracted_age,
                "profile_age": profile_age,
                "age_difference": age_difference,
                "face_match_selfie_to_id": match_selfie_to_id,
                "confidence_selfie_to_id": confidence_selfie_to_id,
                "face_match_selfie_to_profile": match_selfie_to_profile,
                "confidence_selfie_to_profile": confidence_selfie_to_profile
            },
            "verified_badge": True,
            "processing_time": processing_time
        }
        
    except Exception as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        print(traceback.format_exc())
        
        return {
            "verdict": "ERROR",
            "reason": "processing_error",
            "message": str(e),
            "processing_time": round(time.time() - start_time, 2)
        }
    
    finally:
        # SIEMPRE borrar foto temporal
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
                print(f"üóëÔ∏è Foto de verificaci√≥n borrada: {temp_file_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error borrando archivo temporal: {e}")


# ============================================================================
# FUNCI√ìN PRINCIPAL DE VALIDACI√ìN (sin cambios, v3.3)
# ============================================================================

def validate_and_crop_photo(photo_url, photo_type='profile', user_id=None, user_gender=None, user_age=None):
    """Valida y recorta una foto con TODAS las validaciones (v3.3)"""
    start_time = time.time()
    
    try:
        config = VALIDATION_CONFIG.get(photo_type, VALIDATION_CONFIG['profile'])
        
        print("\n" + "="*70)
        print(f"üîç VALIDANDO FOTO v3.4: {photo_type.upper()}")
        if user_id:
            print(f"üë§ Usuario: {user_id}")
        print(f"üìç URL: {photo_url[:80]}...")
        print("="*70)
        
        print("üì• Descargando imagen...")
        img_original = download_image(photo_url)
        print(f"‚úÖ Descargada: {img_original.shape[1]}√ó{img_original.shape[0]} px")
        
        print("üìê Redimensionando...")
        img_resized = resize_image(img_original, max_size=1200)
        print(f"‚úÖ Redimensionada: {img_resized.shape[1]}√ó{img_resized.shape[0]} px")
        
        print("üîç Detectando rostros...")
        faces = face_recognition.face_locations(img_resized)
        num_faces = len(faces)
        print(f"‚úÖ Rostros detectados: {num_faces}")
        
        if num_faces == 0:
            print("‚ùå RECHAZADA: Sin rostros")
            return {
                "verdict": "REJECT",
                "reason": "no_face",
                "message": "No se detect√≥ ning√∫n rostro en la foto",
                "processing_time": round(time.time() - start_time, 2)
            }
        
        if photo_type == 'profile' and num_faces > config['max_faces']:
            print(f"‚ùå RECHAZADA: {num_faces} rostros")
            return {
                "verdict": "REJECT",
                "reason": "multiple_faces",
                "message": f"Se detectaron {num_faces} rostros. Las fotos de perfil deben tener solo una persona",
                "processing_time": round(time.time() - start_time, 2)
            }
        
        face_match_result = None
        if config.get('face_matching_enabled', True):
            print("\nüé≠ VERIFICANDO IDENTIDAD (Face Matching):")
            face_match_result = check_face_matching(img_resized, faces, user_id)
            
            if face_match_result.get('is_match'):
                match_type = face_match_result.get('match_type')
                print(f"   Match: {match_type}")
                print(f"   Identidad: {face_match_result.get('matched_identity')}")
                print(f"   Confianza: {face_match_result.get('confidence'):.1%}")
            else:
                print(f"   Sin matches")
            
            if face_match_result.get('should_reject'):
                print(f"‚ùå RECHAZADA: {face_match_result.get('message')}")
                return {
                    "verdict": "REJECT",
                    "reason": "face_matching_failed",
                    "message": face_match_result.get('message'),
                    "face_matching_data": face_match_result,
                    "processing_time": round(time.time() - start_time, 2)
                }
        
        ai_detection_result = None
        if config.get('ai_detection_enabled', True):
            print("\nü§ñ DETECTANDO IA/DEEPFAKE:")
            ai_detection_result = check_ai_generated(img_resized)
            print(f"   IA detectada: {'S√ç' if ai_detection_result['is_ai_generated'] else 'NO'}")
            print(f"   Confianza: {ai_detection_result['confidence']:.1%}")
            print(f"   Indicadores: {', '.join(ai_detection_result['indicators'])}")
            
            if ai_detection_result.get('should_reject'):
                print(f"‚ùå RECHAZADA: {ai_detection_result.get('message')}")
                return {
                    "verdict": "REJECT",
                    "reason": "ai_generated",
                    "message": ai_detection_result.get('message'),
                    "ai_detection_data": ai_detection_result,
                    "processing_time": round(time.time() - start_time, 2)
                }
        
        nsfw_result = None
        if config.get('nsfw_enabled', True):
            print("\nüîû ANALIZANDO CONTENIDO NSFW:")
            nsfw_result = check_nsfw(img_resized)
            print(f"   Veredicto: {nsfw_result['verdict'].upper()}")
            print(f"   Expl√≠citas: {len(nsfw_result['explicit_detections'])}")
            print(f"   Cuestionables: {len(nsfw_result['questionable_detections'])}")
            
            if nsfw_result['is_nsfw']:
                explicit_parts = [d['part'] for d in nsfw_result['explicit_detections']]
                print(f"‚ùå RECHAZADA: Contenido expl√≠cito ({', '.join(explicit_parts)})")
                return {
                    "verdict": "REJECT",
                    "reason": "nsfw_content",
                    "message": f"Contenido inapropiado detectado: {', '.join(explicit_parts)}",
                    "nsfw_data": nsfw_result,
                    "processing_time": round(time.time() - start_time, 2)
                }
        
        ocr_result = None
        if config.get('ocr_enabled', True):
            print("\nüìù ANALIZANDO TEXTO (OCR):")
            ocr_result = check_text_content(img_resized)
            print(f"   Texto detectado: {ocr_result['text_count']} elementos")
            print(f"   Total caracteres: {ocr_result['total_length']}")
            print(f"   Tel√©fonos: {'S√ç' if ocr_result['has_phone'] else 'NO'}")
            print(f"   URLs: {'S√ç' if ocr_result['has_url'] else 'NO'}")
            print(f"   Palabras prohibidas: {'S√ç' if ocr_result['has_banned_word'] else 'NO'}")
            
            if ocr_result['should_reject']:
                print(f"‚ùå RECHAZADA: {ocr_result['reject_reason']}")
                return {
                    "verdict": "REJECT",
                    "reason": "text_detected",
                    "message": f"Contenido no permitido detectado: {ocr_result['reject_reason']}",
                    "ocr_data": ocr_result,
                    "processing_time": round(time.time() - start_time, 2)
                }
        
        obj_result = None
        if config.get('object_detection_enabled', True):
            print("\nüîç DETECTANDO OBJETOS:")
            obj_result = check_prohibited_objects(img_resized)
            print(f"   Objetos totales: {len(obj_result['all_objects'])}")
            print(f"   Prohibidos: {len(obj_result['prohibited_objects'])}")
            
            if obj_result['has_prohibited']:
                prohibited = [f"{o['object']} ({o['confidence']:.0%})" for o in obj_result['prohibited_objects']]
                print(f"‚ùå RECHAZADA: Objetos prohibidos ({', '.join(prohibited)})")
                return {
                    "verdict": "REJECT",
                    "reason": "prohibited_objects",
                    "message": f"Objetos no permitidos detectados: {', '.join(prohibited)}",
                    "object_data": obj_result,
                    "processing_time": round(time.time() - start_time, 2)
                }
        
        top, right, bottom, left = faces[0]
        
        print("\nüìä AN√ÅLISIS DE CALIDAD:")
        face_area = (bottom - top) * (right - left)
        img_area = img_resized.shape[0] * img_resized.shape[1]
        face_percentage = (face_area / img_area) * 100
        print(f"   % Rostro: {face_percentage:.2f}%")
        
        if face_percentage < 5:
            print("‚ùå RECHAZADA: Rostro muy peque√±o")
            return {
                "verdict": "REJECT",
                "reason": "face_too_small",
                "message": f"El rostro ocupa solo {face_percentage:.1f}%",
                "processing_time": round(time.time() - start_time, 2)
            }
        
        print("\n‚úÇÔ∏è RECORTANDO:")
        cropped, crop_coords = smart_crop_face(img_resized, faces[0], config)
        print(f"   Crop: {crop_coords['width']}√ó{crop_coords['height']} px")
        
        print("\nüîé ANALIZANDO NITIDEZ:")
        sharpness = calculate_face_sharpness(img_resized, faces[0])
        print(f"   Nitidez: {sharpness:.2f}")
        
        if sharpness < config['min_sharpness_review']:
            print(f"‚ùå RECHAZADA: Muy borrosa")
            return {
                "verdict": "REJECT",
                "reason": "blurry",
                "message": f"Foto muy borrosa (nitidez: {sharpness:.1f})",
                "processing_time": round(time.time() - start_time, 2)
            }
        
        target_size = config['target_size']
        cropped_resized = resize_image(cropped, max_size=target_size)
        
        cropped_pil = Image.fromarray(cropped_resized)
        buffer = BytesIO()
        cropped_pil.save(buffer, format='JPEG', quality=90)
        cropped_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        processing_time = round(time.time() - start_time, 2)
        
        needs_review = (
            sharpness < config['min_sharpness'] or
            face_percentage < config['min_face_percentage'] or
            (nsfw_result and nsfw_result.get('verdict') == 'questionable')
        )
        
        if needs_review:
            reasons = []
            if sharpness < config['min_sharpness']:
                reasons.append(f"nitidez baja ({sharpness:.1f})")
            if face_percentage < config['min_face_percentage']:
                reasons.append(f"rostro peque√±o ({face_percentage:.1f}%)")
            if nsfw_result and nsfw_result.get('verdict') == 'questionable':
                reasons.append("contenido cuestionable")
            
            print(f"\n‚ö†Ô∏è REVISI√ìN MANUAL: {', '.join(reasons)}")
            print("="*70 + "\n")
            
            return {
                "verdict": "MANUAL_REVIEW",
                "reason": "quality_review",
                "message": f"Requiere revisi√≥n manual: {', '.join(reasons)}",
                "cropped_image_base64": f"data:image/jpeg;base64,{cropped_base64}",
                "validation_data": {
                    "faces_detected": num_faces,
                    "face_percentage": round(face_percentage, 2),
                    "sharpness": round(sharpness, 2)
                },
                "face_matching_data": face_match_result,
                "ai_detection_data": ai_detection_result,
                "nsfw_data": nsfw_result,
                "ocr_data": ocr_result,
                "object_data": obj_result,
                "processing_time": processing_time
            }
        
        if photo_type == 'profile' and user_id and face_match_result:
            if 'face_encoding' in face_match_result:
                save_user_face_embedding(user_id, face_match_result['face_encoding'])
                print(f"üíæ Embedding guardado para usuario {user_id}")
        
        print("\n‚úÖ APROBADA")
        print("="*70 + "\n")
        
        return {
            "verdict": "APPROVE",
            "cropped_image_base64": f"data:image/jpeg;base64,{cropped_base64}",
            "validation_data": {
                "faces_detected": num_faces,
                "face_percentage": round(face_percentage, 2),
                "sharpness": round(sharpness, 2)
            },
            "face_matching_data": face_match_result,
            "ai_detection_data": ai_detection_result,
            "nsfw_data": nsfw_result,
            "ocr_data": ocr_result,
            "object_data": obj_result,
            "processing_time": processing_time
        }
        
    except Exception as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        print(traceback.format_exc())
        print("="*70 + "\n")
        
        return {
            "verdict": "ERROR",
            "reason": "processing_error",
            "message": str(e),
            "processing_time": round(time.time() - start_time, 2)
        }


# ============================================================================
# RUTAS DE LA API
# ============================================================================

@app.route('/test.html', methods=['GET'])
def test_page():
    try:
        with open('test.html', 'r') as f:
            return f.read()
    except FileNotFoundError:
        return jsonify({"error": "test.html no encontrado"}), 404


@app.route('/health', methods=['GET'])
def health():
    import tensorflow as tf
    gpu_available = len(tf.config.list_physical_devices('GPU')) > 0
    
    return jsonify({
        "status": "ok",
        "service": "ml-validator",
        "version": "3.4",
        "gpu_enabled": gpu_available,
        "features": {
            "face_detection": True,
            "smart_crop": True,
            "face_only_sharpness": True,
            "nsfw_detection": True,
            "ocr_text_detection": True,
            "object_detection": True,
            "face_matching": True,
            "ai_deepfake_detection": True,
            "identity_verification": True,
            "prohibited_objects": list(PROHIBITED_OBJECTS.keys()),
            "blacklist_size": len(face_blacklist),
            "user_faces_db_size": len(user_faces_db)
        }
    })


@app.route('/validate', methods=['POST'])
def validate():
    data = request.get_json()
    
    if not data or 'photoUrl' not in data:
        return jsonify({"error": "photoUrl requerido"}), 400
    
    photo_url = data['photoUrl']
    photo_type = data.get('type', 'profile')
    user_id = data.get('userId')
    user_gender = data.get('userGender')
    user_age = data.get('userAge')
    
    result = validate_and_crop_photo(photo_url, photo_type, user_id, user_gender, user_age)
    
    return jsonify(result)


@app.route('/verify-identity', methods=['POST'])
def verify_identity_api():
    """
    Endpoint de verificaci√≥n de identidad con documento
    
    POST /verify-identity
    Body: {
        "selfieUrl": "https://...",
        "userId": "user_123",
        "profileAge": 28
    }
    """
    data = request.get_json()
    
    if not data or 'selfieUrl' not in data:
        return jsonify({"error": "selfieUrl requerido"}), 400
    
    if 'userId' not in data:
        return jsonify({"error": "userId requerido"}), 400
    
    if 'profileAge' not in data:
        return jsonify({"error": "profileAge requerido"}), 400
    
    selfie_url = data['selfieUrl']
    user_id = data['userId']
    profile_age = int(data['profileAge'])
    
    result = verify_identity_document(selfie_url, user_id, profile_age)
    
    return jsonify(result)


@app.route('/blacklist', methods=['GET', 'POST', 'DELETE'])
def manage_blacklist():
    """Gestionar blacklist de celebridades/personas p√∫blicas"""
    global face_blacklist
    
    if request.method == 'GET':
        return jsonify({
            "blacklist": list(face_blacklist.keys()),
            "count": len(face_blacklist)
        })
    
    elif request.method == 'POST':
        data = request.get_json()
        
        if not data or 'identity' not in data:
            return jsonify({"error": "identity requerido"}), 400
        
        identity = data['identity']
        
        if 'photo_url' in data:
            try:
                img = download_image(data['photo_url'])
                faces = face_recognition.face_locations(img)
                
                if not faces:
                    return jsonify({"error": "No se detect√≥ rostro en la imagen"}), 400
                
                encodings = face_recognition.face_encodings(img, faces)
                face_blacklist[identity] = encodings[0]
                
            except Exception as e:
                return jsonify({"error": f"Error procesando imagen: {str(e)}"}), 500
        
        elif 'face_encoding' in data:
            face_blacklist[identity] = np.array(data['face_encoding'])
        
        else:
            return jsonify({"error": "Requiere photo_url o face_encoding"}), 400
        
        try:
            data_to_save = {k: v.tolist() for k, v in face_blacklist.items()}
            with open(FACE_BLACKLIST_PATH, 'w') as f:
                json.dump(data_to_save, f)
            
            return jsonify({
                "success": True,
                "message": f"Identidad '{identity}' a√±adida a blacklist",
                "blacklist_size": len(face_blacklist)
            })
        except Exception as e:
            return jsonify({"error": f"Error guardando: {str(e)}"}), 500
    
    elif request.method == 'DELETE':
        data = request.get_json()
        
        if not data or 'identity' not in data:
            return jsonify({"error": "identity requerido"}), 400
        
        identity = data['identity']
        
        if identity not in face_blacklist:
            return jsonify({"error": f"Identidad '{identity}' no encontrada"}), 404
        
        del face_blacklist[identity]
        
        try:
            data_to_save = {k: v.tolist() for k, v in face_blacklist.items()}
            with open(FACE_BLACKLIST_PATH, 'w') as f:
                json.dump(data_to_save, f)
            
            return jsonify({
                "success": True,
                "message": f"Identidad '{identity}' eliminada de blacklist",
                "blacklist_size": len(face_blacklist)
            })
        except Exception as e:
            return jsonify({"error": f"Error guardando: {str(e)}"}), 500


# ============================================================================
# INICIO DEL SERVIDOR
# ============================================================================

if __name__ == '__main__':
    print("\n" + "="*70)
    print("üöÄ ML VALIDATOR v3.4 - COMPLETE VALIDATION + IDENTITY VERIFICATION")
    print("="*70)
    print("\nüìç ENDPOINTS:")
    print("   ‚Ä¢ Health:          GET    http://192.168.1.159:5000/health")
    print("   ‚Ä¢ Validate:        POST   http://192.168.1.159:5000/validate")
    print("   ‚Ä¢ Verify Identity: POST   http://192.168.1.159:5000/verify-identity")
    print("   ‚Ä¢ Blacklist:       GET/POST/DELETE http://192.168.1.159:5000/blacklist")
    print("   ‚Ä¢ Test UI:         GET    http://192.168.1.159:5000/test.html")
    
    print("\n‚öôÔ∏è CONFIGURACI√ìN:")
    print("   ‚Ä¢ Profile:  face‚â•10%, sharpness‚â•50, 1 rostro, NSFW, OCR, Objetos, Face Match, AI Detection")
    print("   ‚Ä¢ Album:    face‚â•5%,  sharpness‚â•40, ‚â§5 rostros, NSFW, OCR, Objetos, Face Match")
    
    print("\nüö´ OBJETOS PROHIBIDOS:")
    for obj, cfg in PROHIBITED_OBJECTS.items():
        print(f"   ‚Ä¢ {obj}: threshold={cfg['threshold']:.0%}, severity={cfg['severity']}")
    
    print(f"\nüé≠ FACE MATCHING:")
    print(f"   ‚Ä¢ Blacklist: {len(face_blacklist)} identidades")
    print(f"   ‚Ä¢ BD Usuarios: {len(user_faces_db)} usuarios registrados")
    
    import tensorflow as tf
    gpus = tf.config.list_physical_devices('GPU')
    
    if gpus:
        print(f"\n‚ö° GPU: {len(gpus)} dispositivo(s)")
        for gpu in gpus:
            print(f"   ‚Ä¢ {gpu.name}")
    else:
        print("\n‚ö†Ô∏è CPU MODE")
    
    print("\n" + "="*70)
    print("üéØ VALIDACIONES v3.4:")
    print("   ‚úÖ Face detection (GPU)")
    print("   ‚úÖ Smart crop + face-only sharpness")
    print("   ‚úÖ NSFW detection (NudeNet)")
    print("   ‚úÖ OCR - Text/Phone/URL detection (EasyOCR)")
    print("   ‚úÖ Prohibited objects (YOLOv8)")
    print("   ‚úÖ Face Matching - Celebrity/impersonation detection")
    print("   ‚úÖ AI/Deepfake detection")
    print("   ‚úÖ Identity Verification - ID/C√©dula verification (NEW v3.4)")
    print("="*70 + "\n")
    
    app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)
