/**
 * NSFW Content Detection usando nsfwjs
 * ESTRATEGIA FINAL V2: SOLO Sistema de Denuncias
 * 
 * IMPORTANTE: Para protecci√≥n infantil (sitio NO +18)
 */

import * as nsfwjs from 'nsfwjs';

/**
 * CONCLUSI√ìN DEFINITIVA:
 * 
 * NSFW.js NO ES CONFIABLE para distinguir contenido inapropiado:
 * - Desnudos reales ‚Üí PASAN (Porn: 40-80%)
 * - Ilustraci√≥n rom√°ntica vestida ‚Üí RECHAZADA (Drawing: 67%)
 * - Foto supermercado ‚Üí 91% porn
 * - Misma mujer, mismo vestido: resultados opuestos
 * 
 * ESTRATEGIA FINAL:
 * ‚ùå NO usar filtro autom√°tico NSFW.js
 * ‚úÖ S√ç analizar pero NO rechazar
 * ‚úÖ Guardar scores para estad√≠sticas
 * ‚úÖ Confiar 100% en denuncias de usuarios
 * ‚úÖ Auto-hide tras 3 denuncias
 * 
 * RAZ√ìN:
 * - Sin recursos para moderaci√≥n humana 24/7
 * - NSFW.js genera m√°s problemas que soluciones
 * - Mejor dejar que comunidad modere
 * - Plataformas grandes (Instagram, TikTok) tambi√©n dependen de denuncias
 */

// NO hay umbrales - Todo pasa, solo guardamos scores para estad√≠sticas
export const NSFW_ANALYSIS_MODE = 'log_only'; // Solo registrar, no bloquear

let model: nsfwjs.NSFWJS | null = null;

/**
 * Cargar modelo NSFW (solo una vez)
 */
export async function loadNSFWModel(): Promise<nsfwjs.NSFWJS> {
  if (model) return model;
  
  try {
    console.log('ü§ñ Cargando modelo NSFW...');
    model = await nsfwjs.load();
    console.log('‚úÖ Modelo NSFW cargado');
    return model;
  } catch (err) {
    console.error('‚ùå Error cargando modelo NSFW:', err);
    throw err;
  }
}

/**
 * Analizar una imagen para detectar contenido NSFW
 * @param file - Archivo de imagen a analizar
 * @returns true si es segura, false si contiene contenido expl√≠cito
 */
export async function isImageSafe(file: File): Promise<{
  safe: boolean;
  reason?: string;
  scores?: any;
}> {
  try {
    // Cargar modelo si no est√° cargado
    const nsfwModel = await loadNSFWModel();
    
    // Crear elemento de imagen
    const img = document.createElement('img');
    const imageUrl = URL.createObjectURL(file);
    
    return new Promise((resolve) => {
      img.onload = async () => {
        try {
          // Analizar imagen
          const predictions = await nsfwModel.classify(img);
          
          // Limpiar URL
          URL.revokeObjectURL(imageUrl);
          
          // Convertir predictions a objeto
          const scores: any = {};
          predictions.forEach(pred => {
            scores[pred.className] = pred.probability;
          });
          
          // Extraer puntuaciones
          const pornScore = scores['Porn'] || 0;
          const sexyScore = scores['Sexy'] || 0;
          const hentaiScore = scores['Hentai'] || 0;
          const neutralScore = scores['Neutral'] || 0;
          const drawingScore = scores['Drawing'] || 0;
          
          console.log('üîç NSFW Analysis (LOG ONLY - NO BLOCKING):', {
            Porn: `${(pornScore * 100).toFixed(1)}%`,
            Sexy: `${(sexyScore * 100).toFixed(1)}%`,
            Hentai: `${(hentaiScore * 100).toFixed(1)}%`,
            Neutral: `${(neutralScore * 100).toFixed(1)}%`,
            Drawing: `${(drawingScore * 100).toFixed(1)}%`,
            '‚ö†Ô∏è': 'MODO SOLO-LOG: No se rechaza nada autom√°ticamente',
            'üõ°Ô∏è': 'Protecci√≥n: Sistema de denuncias + Auto-hide tras 3 reportes'
          });
          
          // ====== SIEMPRE APROBAR ======
          // Guardar scores para estad√≠sticas, pero NO rechazar
          // Sistema de denuncias se encarga de la moderaci√≥n
          
          console.log(`‚úÖ APROBADO (modo solo-log): Confiamos en denuncias de usuarios`);
          resolve({
            safe: true,
            scores,
            // Incluir scores para guardar en BD (estad√≠sticas)
            metadata: {
              pornScore,
              sexyScore,
              hentaiScore,
              neutralScore,
              drawingScore,
              analyzedAt: new Date().toISOString()
            }
          });
        } catch (err) {
          console.error('Error analizando imagen:', err);
          // En caso de error, permitir la imagen (fail-safe)
          resolve({ safe: true });
        }
      };
      
      img.onerror = () => {
        URL.revokeObjectURL(imageUrl);
        // En caso de error, permitir la imagen (fail-safe)
        resolve({ safe: true });
      };
      
      img.src = imageUrl;
    });
  } catch (err) {
    console.error('Error en isImageSafe:', err);
    // En caso de error, permitir la imagen (fail-safe)
    return { safe: true };
  }
}

/**
 * Analizar m√∫ltiples im√°genes
 * @param files - Array de archivos a analizar
 * @returns Array con resultados
 */
export async function analyzeImages(files: File[]): Promise<Array<{
  file: File;
  safe: boolean;
  reason?: string;
}>> {
  const results = [];
  
  for (const file of files) {
    const result = await isImageSafe(file);
    results.push({
      file,
      safe: result.safe,
      reason: result.reason
    });
  }
  
  return results;
}
